# -*- coding: utf-8 -*-
"""Siren.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11zGKjQU2HezLOlaLGrUkOQJws1YK-F6_

# **Siren MLP**

The Siren MLP, published in the paper **Implicit Neural Representations with Periodic Activation Functions** is a novel architecture that explores the usage of sinusoidal activations in fitting problems. By overfitting the model on a single sample, the Siren model can accurately reconstruct the sample and its gradients. 

In this notebook we will be training the Siren MLP on an oriented point cloud, and reconstructing its Signed Distance Function (SDF). The SDF is a function $ f(\mathbf{x} ; \mathcal{m}) : \mathbb{R}^3 \rightarrow \mathbb{R}$, i.e it maps an arbitrary point $\mathbf{x}$ of 3d space to its distance from the 3d object $\mathcal{m}$. If the point lies on the surface of $\mathcal{m}$, then the distance is 0, whereas if the point lies outside or inside the object, then the distance is positive/negative respectively.

In order to visualize and evaluate the resulting SDF we will use an isosurfacing operation called "Marching Cubes". This script will generate a mesh from the SDF, which we can then visualize as we normally would.

**Usage Instructions**

Download the .zip file from eclass and upload it on google colab. You can do that in 2 ways by following the instructions below. Extract the contents and then install all the relevant libraries (you can do so by running the cells provided below). In the "data" folder you will upload the sample you want to fit and reconstruct. The sample must be an **oriented point cloud** in ".xyz" format (that is, points along with their respective normal vectors). You can convert a mesh into an oriented point cloud using the open source tool [Meshlab](https://www.meshlab.net/).

The code cells tend to get quite large, so for the sake of simplicity we use these code cells to call scripts from .py files. You are welcome to look into the code if interested. 

**Disclaimer**

The code is taken directly from the authors' [github](https://github.com/vsitzmann/siren/tree/4df34baee3f0f9c8f351630992c1fe1f69114b5f) and it has been trimmed so that it exclusively contains SDF-relevant code. The reader is encouraged to visit their repository and play around with the various visual tools they have created.

In order to access the source files there are two options: [option 1](#option1) and [option 2](#option2):

<a name="option1"></a>

# **Option 1**

If you are connected to a google account on this computer then you can go with option 1. If you are not, option 1 will ask for your credentials. Keep in mind that it does not actually have access to your account, but it is required to download the files from the external drive.

First run the following cell and perform the authentication procedure.
"""

#PyDrive to access external google drive
!pip install PyDrive

#----------Connect to google drive-----------
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

"""After successfully authenticating your google account you may proceed on the following code cell. Paste the drive link on the *link* string variable and run the cell. After it completes running, click refresh on the files tab to the left, and a file named "siren.zip" should appear. 

If this operation is performed successfully you may proceed with the exercise.
"""

link = "https://drive.google.com/file/d/1WrtFLFhmPrFUXpzeZllEFAZ1KARZWhPp/view?usp=sharing"
start_index = link.index("/d/") + 3
end_index = link.index("/view") 

file_ID = link[start_index:end_index]

downloaded = drive.CreateFile({'id': file_ID})
downloaded.GetContentFile('siren.zip')

"""<a name="option2"></a>

# **Option 2**

If for some reason you do not have a google account, are reluctant to use it, or option 1 failed for some reason, then download the file provided in the link, and after downloading upload it to this colab's workspace.

After this is complete a "siren.zip" file should appear and you may proceed with the exercise.
"""

#----------Unzip the file----------
!unzip siren.zip

"""# **Install required modules**"""

#---Install all relevant libraries--

#Pytorch
!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113
#Scipy, scipy image & video
!pip3 install scipy
!pip3 install scikit-image
!pip3 install scikit-video
!pip3 install plyfile
!pip3 install open3d

"""# **Train the model by running the train script**

In order to properly run your script you are going to require access to a gpu. Click on 'Runtime' -> 'Change Runtime Type' and select 'GPU'. You can test that the code works by using the sample object "thai_statue.xyz". After verifying that you can properly train the model, replace it with the object you want and train again.

The training procedure should be relatively fast, no need for hundreads of epochs. Just 25-30 should do.
"""

#Run the experiment script, make sure that you are using a cuda runtime.

!python ./experiment_scripts/train_sdf.py armadillo_low_low1.xyz

"""# **Assert that the model has been trained correctly**

In order to ensure that our model has been trained correctly, we will visualize the sdf using an isosurfacing operation called "marching cubes". This will create a mesh from the sdf, which should closely resemble the original one.

After running the train script for an arbitrary number of epochs, when the cell above stops executing, a directory should appear in the file explorer containing "checkpoints". Naturally, when we train a neural network we need to save its weights and biases so that we can use it in a downstream application. Checkpoints do just that. They are saved states of the same neural network, but trained for a different number of epochs.

Locate the checkpoint you want to use the test script on, copy the file name and pass it as an argument to the script below.
"""

#Run the evaluation script

!python ./experiment_scripts/test_sdf.py 9999

"""Now download the extracted .ply file in "./logs/exp1/" and MeshLab to visualize the results. You can use any mesh visualization tool to do so. The output mesh should very closely resemble the original one. Once you verify that this is true, you can proceed to run the following code cell."""

import os
import sys

sys.path.append("/content")

import torch
import modules, utils

model_type = "sine"
mode = "mlp"
resolution = 512
logging_root = "./logs"
experiment_name = "exp1"
checkpoint_to_load = "0999" #WRITE THE CHECKPOINT YOU WANT TO LOAD HERE
checkpoint_path = f"./logs/{experiment_name}/checkpoints/model_epoch_{checkpoint_to_load}.pth"

class SDFDecoder(torch.nn.Module):
    def __init__(self):
        super().__init__()
        # Define the model.
        if mode == 'mlp':
            self.model = modules.SingleBVPNet(type=model_type, final_layer_factor=1, in_features=3)
        elif mode == 'nerf':
            self.model = modules.SingleBVPNet(type='relu', mode='nerf', final_layer_factor=1, in_features=3)
        self.model.load_state_dict(torch.load(checkpoint_path))
        self.model.cuda()

    def forward(self, coords):
        model_in = {'coords': coords}
        return self.model(model_in)['model_out']


sdf_decoder = SDFDecoder()

"""Once the cell above has been ran, we now have access to a trained model which we can use to get values of our object's sdf at particular points in space. We are now going to use the sdf in order to perform collision detection. The model takes as input a batch of query points ( torch.Tensor with size B x 3).

*  In your main program (c++) you will throw a ball and save its trajectory to a file, as a series of points. 
*  You will then upload the file on this colab and load the points
*  Create a torch.Tensor containing the points and feed them to the model.
*  Use the sdf's values to detect a collision in your main program, and create a response accordingly.
"""

#EXAMPLE - Creating a torch tensor of points, querying the model and printing the output.
point = torch.Tensor([[0,-0.2,0],[100,100,100]]).cuda()
out = sdf_decoder(point)
print(out)

#You can begin writing your code in this cell, using the provided rough outline:
#-------------------------------------------------------------------------------
from google.colab import drive
drive.mount('/content/drive')
#Load the trajectory points from the file
#...
f = open("/content/drive/MyDrive/Colab Notebooks/points.txt", "r")
#Build a torch Tensor
#...
Lines = f.readlines()
count = 0
point_array = []
for line in Lines:
  str_cords = line.split()
  x = float(str_cords[0])
  y = float(str_cords[1])
  z = float(str_cords[2])
  p = [x,y,z]
  point_array.insert(count,p)
  count+=1
f.close()
print(point_array)
point_tensor = torch.Tensor(point_array).cuda()
#Run the model
#...
output_sdf = sdf_decoder(point_tensor)
print(output_sdf)
#Save the output to a file
#...
f2 = open("/content/drive/MyDrive/Colab Notebooks/sdf.txt","w")
f2.write("")
f2.close()
f3 = open("/content/drive/MyDrive/Colab Notebooks/sdf.txt","a")
for i in range(0,count-1):
  s = str(output_sdf[i][0])
  temp = s.split("(")
  temp_s = temp[1]
  temp2 = temp_s.split(",")
  final_s = temp2[0]
  string = final_s + "\n"
  f3.write(string)
f3.close()
#Now go back to your original program and use the provided sdf values. If they
#are <0 it means there's a collision!



"""**Common Errors**



*   "Directory/File not found" -> Open the train_sdf/test_sdf scripts and play around with the checkpoint paths
*   "Large memory allocation" -> Reduce the "resolution" parameter in the test_sdf.py script.
*   "Module PIL has not attribute "Resampling"" -> expand the call stack and locate the file that causes the error. There should be several instances of using "PIL.Image.Resampling.BICUBIC". If you replace all of them with PIL.Image.BICUBIC the code should run without problems.

Make sure to use google. All the tools you'll need are available, you just need to search for them :)
"""